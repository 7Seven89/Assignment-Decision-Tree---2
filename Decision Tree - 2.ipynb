{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d624c02-a894-4265-ad6a-287e28060075",
   "metadata": {},
   "source": [
    "# Diabetes Prediction Using Decision Tree\n",
    "\n",
    "## Objective:\n",
    "Create a decision tree to predict whether a patient has diabetes based on clinical variables.\n",
    "\n",
    "## Dataset Information:\n",
    "The dataset contains the following variables:\n",
    "1. **Pregnancies**: Number of times pregnant (integer)\n",
    "2. **Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test (integer)\n",
    "3. **BloodPressure**: Diastolic blood pressure (mm Hg) (integer)\n",
    "4. **SkinThickness**: Triceps skin fold thickness (mm) (integer)\n",
    "5. **Insulin**: 2-Hour serum insulin (mu U/ml) (integer)\n",
    "6. **BMI**: Body mass index (weight in kg/(height in m)^2) (float)\n",
    "7. **DiabetesPedigreeFunction**: A function scoring the likelihood of diabetes based on family history (float)\n",
    "8. **Age**: Age in years (integer)\n",
    "9. **Outcome**: Class variable (0 if non-diabetic, 1 if diabetic) (integer)\n",
    "\n",
    "## Steps to Follow:\n",
    "### Q1. Import the Dataset and Examine the Variables\n",
    "- Import the dataset using pandas.\n",
    "- Use descriptive statistics to understand the distribution of each variable.\n",
    "- Create visualizations to explore the relationships between the variables.\n",
    "\n",
    "### Q2. Preprocess the Data\n",
    "- **Handle Missing Values**:\n",
    "  - Replace zeros in `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, and `BMI` with `NaN`.\n",
    "  - Fill missing values with appropriate statistics (e.g., median).\n",
    "- **Remove Outliers**:\n",
    "  - Use the IQR rule to identify and remove outliers in critical numerical columns.\n",
    "- **Transform Variables**:\n",
    "  - Convert categorical variables into dummy variables if required.\n",
    "\n",
    "### Q3. Split the Dataset\n",
    "- Split the dataset into training and test sets using an 80-20 split.\n",
    "- Use a random seed to ensure reproducibility.\n",
    "\n",
    "### Q4. Train the Decision Tree\n",
    "- Use a decision tree algorithm (e.g., ID3 or C4.5) to train the model on the training set.\n",
    "- Perform cross-validation to optimize hyperparameters and prevent overfitting.\n",
    "\n",
    "### Q5. Evaluate the Model\n",
    "- Use metrics such as accuracy, precision, recall, and F1 score to evaluate the model on the test set.\n",
    "- Visualize the results using confusion matrices and ROC curves.\n",
    "\n",
    "### Q6. Interpret the Decision Tree\n",
    "- Analyze the tree structure, including splits, branches, and leaves.\n",
    "- Identify the most important variables and thresholds.\n",
    "- Use domain knowledge to explain patterns and trends.\n",
    "\n",
    "### Q7. Validate the Model\n",
    "- Apply the decision tree model to new data to validate its performance.\n",
    "- Test the robustness of the model to changes in the dataset or environment using sensitivity analysis and scenario testing.\n",
    "\n",
    "## Dataset Link:\n",
    "[Download diabetes.csv dataset](https://drive.google.com/file/d/1Q4J8KS1wm4-_YTuc389enPh6O-eTNcx2/view?usp=sharing)\n",
    "\n",
    "By following these steps, you will develop a comprehensive understanding of decision tree modeling and its applications in healthcare.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2bad3-a60c-4398-a91e-21db42998657",
   "metadata": {},
   "source": [
    "## Q1. Importing and Examining the Dataset\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://drive.google.com/uc?id=1Q4J8KS1wm4-_YTuc389enPh6O-eTNcx2\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Overview of the dataset\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Visualizing distributions\n",
    "data.hist(figsize=(12, 10), bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c032fc-1c57-48f7-bff2-43e721ef0d7e",
   "metadata": {},
   "source": [
    "## Q2. Preprocessing the Data\n",
    "\n",
    "### Steps:\n",
    "1. **Check for Missing Values**:\n",
    "   - Replace zeros in columns such as `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, and `BMI` with `NaN`.\n",
    "   - Handle missing data by filling the missing values with the median of the respective columns.\n",
    "\n",
    "2. **Remove Outliers**:\n",
    "   - Use the Interquartile Range (IQR) rule to identify and remove extreme values from the dataset.\n",
    "\n",
    "3. **Scale Features**:\n",
    "   - Normalize or standardize the numerical features for consistent scale and better performance of machine learning models.\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "# Replace zeros with NaN for specific columns\n",
    "columns_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "data[columns_with_zeros] = data[columns_with_zeros].replace(0, np.nan)\n",
    "\n",
    "# Fill missing values with median\n",
    "for col in columns_with_zeros:\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "# Remove outliers using the IQR method\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Apply outlier removal to selected columns\n",
    "for col in ['Glucose', 'BloodPressure', 'BMI', 'Age']:\n",
    "    data = remove_outliers(data, col)\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']] = scaler.fit_transform(\n",
    "    data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    ")\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd561ef-1559-4f7b-89d9-1c426900b48d",
   "metadata": {},
   "source": [
    "## Q3. Splitting the Dataset\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting data into features and target\n",
    "X = data.drop(columns=['Outcome'])\n",
    "y = data['Outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c24c3-8a08-425f-b101-b49685383f45",
   "metadata": {},
   "source": [
    "## Q4. Training a Decision Tree Model\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd877a9-6487-4c06-9578-d6f7011c7fea",
   "metadata": {},
   "source": [
    "## Q5. Evaluating the Model\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Metrics\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC Curve\n",
    "y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62003bff-a515-4a9f-b5d9-d6003f7c5955",
   "metadata": {},
   "source": [
    "## Q6. Interpreting the Decision Tree\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_model, feature_names=X.columns, class_names=[\"Non-Diabetic\", \"Diabetic\"], filled=True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- Analyze the tree splits, branches, and leaf nodes.\n",
    "- Identify key features like Glucose, BMI, and Age.\n",
    "- Discuss threshold values and their relevance to diabetes prediction.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a563bf2-08ba-4c20-a5fd-2d3a521264aa",
   "metadata": {},
   "source": [
    "## Q7. Validating the Model\n",
    "\n",
    "### Steps:\n",
    "1. Test with new unseen data.\n",
    "2. Use sensitivity analysis by altering features slightly and observing predictions.\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "# Sensitivity Analysis\n",
    "new_data = X_test.copy()\n",
    "new_data['Glucose'] += 0.1  # Simulate a small increase in glucose\n",
    "new_predictions = best_model.predict(new_data)\n",
    "\n",
    "# Compare results\n",
    "print(\"Original Predictions:\", y_pred[:10])\n",
    "print(\"New Predictions after Glucose adjustment:\", new_predictions[:10])\n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
